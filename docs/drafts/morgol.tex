\documentclass[11pt]{article}
\usepackage{../inc/style}
\title{Morgol specifications}

\def\discuss#1{\begingroup\par\leftskip2em {\footnotesize {\bf Discussion:} #1} \par\endgroup}
\def\say#1#2{\begingroup\par\leftskip4em {\bf #1:} \it #2\par\endgroup}

\begin{document}
\section*{Syntax}
Built-in parsers: {\tt ident} (identifier string), {\tt longLit}, {\tt doubleLit} and {\tt stringLit} (quoted string), type declaration: ${\tt type}\in\{{\tt long}, {\tt double}, {\tt string}, {\tt date}\}$ additional types might be converted during the parsing phase. For conciseness, we use the following syntactic sugar: \verb$rs(a,b) := (a (b a)*)?$ and \verb$rs1(a,b) := a (b a)*$. We use comments: {\tt //...\textbackslash n} and {\tt /*...*/}.
\discuss{Using // and /* */ only brings coherency with other languages but breaks compatibility with {\tt----} SQL-like comments. Similarly, should our language be case-sensitive or case-insensitive? To which extend do we keep legacy compatibility? Similarly should we remove useless keywords \textit{create} and \textit{declare}?
	\say{Thierry}{Be disruptive for simplicity, coherence and ease of use. As language is declarative, we can ignore keywords case but preserve it for variables. Remove verbosity as long as it is easy to understand.}
	\say{Milos}{We want to keep compatibility with SQL declarations.}
}
The system declaration file format is defined as follows:
\begin{verbatim}
system ::= source* mapdef* query* trigger*
\end{verbatim}

\subsubsection*{Sources}
\begin{verbatim}
source ::= "CREATE" ("STREAM" | "TABLE") schema "FROM" input split adaptor ";"
schema ::= name "(" rs1(field type, ",") ")"
input  ::= "FILE" quotedPath
split  ::= "LINE" "DELIMITED"
         | quotedSeparator "DELIMITED"
         | "FIXEDWIDTH" sizeInBytes
         | "PREFIX" headerBytes
adaptor ::= name "(" rs(option ":=" value, ",") ")"
\end{verbatim}
Source is either input stream (content varies while the program is running and generate events) or fixed tables (constant relations). The implemented adaptors and their respective options are:\ul
\item {\tt ORDERBOOK}: finance events in CSV, with the columns: {\tt transaction\_id}:int, {\tt broker\_id}:int, {\tt evt\_type}:string$\in\{B,S,E,D\}$ (place bid, place ask, match, cancelled), {\tt volume}:int, {\tt price}:double.\ul
	\item {\tt brokers}: number of brokers (integer)
	\item {\tt bids}, {\tt asks}: stream names as stringLit
	\item {\tt deterministic}: boolean defining whether broker id is assigned randomly
	\ule
\item {\tt CSV}\ul
	\item {\tt name}: string, schema name
	\item {\tt schema}: stringLit of comma-separated types
	\item {\tt delimiter}: column delimiter as string, by default a comma
	\item {\tt action} $\in\{\text{insert, delete, both}\}$. If both, first column denotes the transaction\_id, the second is $\in\{0,1\}$ and is 1 if it is an insertion, following columns are the tuple.
	\ule
\ule

\subsubsection*{Expressions}
\begin{verbatim}
expr   ::= "(" expr ")" | ...
mapref ::= name "[" rs(key, ",") "]"
add    ::= expr "+" expr
mul    ::= expr "*" expr
aggsum ::= "Sum" "(" ("[" rs(key, ",") "]" ",")? expr ")"
exists ::= "Ex" "(" expr ")"
lift   ::= "(" ident "=" expr ")" // discuss := or =
cmp    ::= "{" expr opt(("=="|"!="|">"|"<"|">="|"<=") expr) <"}"
apply  ::= ident "(" rs(expr, ",") ")" // type inferred from library
ref    ::= ident
const  ::= longLit | doubleLit | stringLit
\end{verbatim}
% aggmin ::= "Min" "(" ("[" rs(key, ",") "]" ",")? expr ")"
% aggmax ::= "Max" "(" ("[" rs(key, ",") "]" ",")? expr ")"

Changes are mostly minor syntax changes: we replace table access syntax by map references because they are stored uniformly and there is no reason making a syntactical difference. Exists gets reduced in 'Ex', we replace the lift by '=' and comparison by '=='. Function calls could be simplified if we have reserved keywords for the AggSum and Exists operations, and if we can refer to a library to type check function return and argument types.
\discuss{Do we want to preserve notation as compatible as possible with SQL or not ?}
\discuss{Do we introduce explicit AggMin and AggMax operations or are these handled by maps?}

\subsubsection*{Maps (internal structures)}
\begin{verbatim}
mapdef ::= "DECLARE" "MAP" name "[" rs(key, ",") "]" ("[" rs(aggkey, ",") "]")? 
                                 (":" type)? ":=" expr ";" mapopt*
key    ::= ident ":" type
aggkey ::= ("min"|"max"|"sum") "(" ident ")" ":" type
mapopt ::= "SET " mapName "." rs(ident,".") ":=" value ";"
\end{verbatim}

The options that can be declared for a map are the location and the value threshold. The first one correspond to one or multiple tags (logical group name), where nodes joining the cluster will bear one or multiple tag. The threshold is the relative difference in keys/values for a tuple to be considered for updating. This only applies to double types. \discuss{Not clear to which field the threshold relates. Do we need other options ?}

{\color{red}
XXX: undecided what multiplicity if two aggregation for my case => use filter keyword ?\\
XXX: milos' issue: if we have only multiplicity 1 we can put aggr in multiplicity\\
XXX: mark for inequality comparison internally ? (maintain in tree)
}

The map type can be omitted if the map's value type is {\tt long}. The first set of keys are treated as regular map keys. The second set of keys are aggregations. They behave similarly as regular map keys for writing/updating but return the aggregation when they are read.
\discuss{It is not very clear whether aggregation keys should be separated from other keys as they must be provided for addition and deletion, but are read differently.
	\say{Thierry}{Keep them together as we need these values (before aggregation) for updates such that we can efficiently maintain aggregate value in the underlying data structure.}
	\say{Milos}{Keep them separate as they have a different semantics.}
}
For recursion, we consider that a tuple has changed if it is addition creates a change to the map being read. This can be either: an insertion/deletion, a modification in the value (multiplicity), or a change of the aggregated values.
\discuss{We need to detect these "modifications" efficiently and compute its delta over the map to create a reaction to it (call other triggers with updates values). It is not clear how a change in an aggregate value will be treated. Should it be a "deletion/insertion" (not desirable because if we have deletion, we have endless loop in shortest path) or a "value update"?
	\say{Thierry}{I think there is many issues in the nitty gritty details of the implementation that we didn't covered so far.}
We still do not achieve the effect that is claimed in SociaLite: having one single map to compute the shortest path \textit{and} computing its multiplicity. What should the return value of a map containing aggregations?
	\say{Thierry}{The returned value should be the multiplicity of the min/max/sum so that we can achieve average and counting easily. We can easily modify it by wrapping into an exists. The shortest path iteration should be done with the number of added tuples.}
	\say{Milos}{Returned value should be 1 when there is aggregted values (1 aggregate tuple). The number of shortest path is computed using two different maps, one for the minimum length, one for the count.}
}


A stream might have an associated map if it is explicitly referred to. A table must have an associated map in which the table will be loaded. A table does not generate trigger whereas there are always triggers associated with a stream.

Maps can be defined in terms of calculus

add extra maps and extra triggers

add recursion


\subsubsection*{3. Queries (output)}
A query is simply a reference to a map that will be made visible outside of the system:
\begin{verbatim}
query ::= "DECLARE" "QUERY" externalName ":=" mapName ";"
\end{verbatim}

\subsubsection*{4. Triggers (user-defined)}
\begin{verbatim}
trigger ::= "ON" ("+"|"-") streamName "(" ident ("," ident)* ")" "{" (stmt)* "}"
          | "ON" "SYSTEM" "READY" "{" (stmt)* "}"
stmt    ::= mapref (":" "(" expr ")")? ("+="|":=") expr ";"
\end{verbatim}

rename system ready by a single word ?




\section*{Semantics}
XXX: write down M3 semantics.
Semantics is very similar to M3 language, we only describe differences here.
AggMin, AggMax

AggMin, AggMax, retain only one single value per key. This correspond either to zero if the 

\section*{Examples}
\subsubsection*{Problem 1: betweenness centrality}
Let our fact table be $edge(x,y)$ we want to compute the \href{http://en.wikipedia.org/wiki/Betweenness_centrality}{betweenness centrality} $g(v)$ of graph nodes $v$, we apply the following rules:
\def\Ex{{\rm Ex}}
\[\begin{array}{rcl}
edge[x,y] & := & \text{\it storage of input stream} \\

spath[] \\

path[x,y,len] & := & \Ex(edge[x,y]) \times (len\hat= 1) +  Ex(edge[x,z]) \times Ex(path[z,y,l]) \times (len\hat= 1+l) \times (x\ne y)\\
path_v[x,y,v,len] & := & Ex(path[x,v,l_1]) \times Ex(path[v,y,l_2]) \times (len\hat= l_1+l_2) \times (x\ne y) \\
centrality[v] & := & Ex(path[x,y,m]) \times (Ex(path[x,y,s] \times (s<m)) = 0) \times \left(\dfrac{{\rm Sum}(path_v[x,y,v,m])}{path[x,y,m]}\right)
\end{array}\]







--------------------------------------------------------------

XXX: find more problems from papers (Socialite?)


By adding the condition $(x\ne y )$ in the $path$ definition, we prevent cycles.

\subsubsection*{Problem 2: PageRank}
The iterative method of \href{http://en.wikipedia.org/wiki/PageRank#Iterative}{PageRank} is defined for $N$ pages with a matrix $M=(K^{-1} A)^T$ where $A$ is the adjacency matrix of the graph, $K$ the diagonal matrix with out-degrees in diagonal. We compute \[R(t+1)=d\cdot M\cdot R(t)+\dfrac{1-d}{N}{\bf 1} \qquad \text{with {\bf 1} a column vector of 1 and }R(0)={\bf 1}\cdot \frac{1}{n}\]
The issues with the matrix model is that all computation are done synchronously.

\textbf{Naive version:} To avoid explicit synchronization, we have 2 solutions: maintaining versions in the database or normalizing $|R|=1$ after every computation.
\[\begin{array}{rrl}
node[x] &:=& \text{\it input stream} \in\{0,1\} \\
edge[x,y] &:=& \text{\it input stream, adjacency matrix} \\
weight[x] &:=& node[x] \times (w_0\hat=weight[x]) \times \left( w_0 + (w_1\hat=nw) \times \left(
\dfrac{|w_1 - w_0|}{w_1+w_0} > {\rm threshold}\right) \times (w_1-w_0) \right) \\ \\
&& \text{where } nw= {\rm AggSum}([], \dfrac{edge[y,x] \times weight[y]}{{\rm AggSum}([],edge[y,z])}) \times d + \dfrac{1-d}{{\rm AggSum}([],node[v])}\\
\end{array}\]
The shortcomings with this approach are the non-preservation of global weight and injection of initial coefficient. The $d$ weighting should mitigates this issue (but not sure at all !!). We also must ensure that we don't call recursively if the value did not change (encode this with threshold in map declaration or in another function?).

\textbf{Clock join:} One possible idea to virtually execute the program synchronously is to have a clock stream and a timestamp attribute for all maps. When a clock tick is inserted, the next iteration can be computed (join $data \times tick$); when the tick is removed, the associated data can be removed from the map. Issues:\ul
\item Deletion trigger of weight must be \underline{overridden} to only remove data (and avoid recursion).
\item How to know that all the data at a tick has been fully computed ?
\ule
\[\begin{array}{rrl}
tick[t] &:=& \text{\it logical clock} \in \{0,1\} \\
node[x] &:=& \text{\it input stream} \in\{0,1\} \\
edge[x,y] &:=& \text{\it input stream} \\
weight[x,t] &:=& node[x] \ \times {\rm AggSum}([x], \dfrac{edge[y,x] \times weight[y,t-1]}{{\rm AggSum}([],edge(y,z))}) \times d + \dfrac{1-d}{{\rm AggSum}([],node[z])}
\end{array}\]

--------------------------------------------------------------
















\section*{Roadmap}
Goals:\ul
\item Find use cases and examples
\item Design the language, allow incrementalization by reusing most of existing infrastructure, and combine the power of datalog and triggers.
\item Get a clean and simple semantics that can be used and understood easily in various domains: windowed streams, state machine, continuous queries.
\item Define distribution strategy
\item Data locality: optional location specification. Must be orthogonal to other concerns (tag with @all, @group, @hashed ?)
\item Simulate timestamps / iteration numbers
\ule

Integrate features from
Socialite\cite{socialite},
WebDamLog\cite{webdamlog},
Bloom lattices\cite{bloom_lattices},
Dedalus\cite{dedalus},
CALM\cite{bloom_calm},
Pregel\cite{pregel},
DatalogFS\cite{datalog_fs} in DBToaster\cite{dbtoaster09,dbtoaster11}.

--------------------------------------------------------------

{\color{red}
XXX: for non-stratified programs, provide the user facilities like $<+, <-$ to do operations at the next step.
XXX: we need to be able to define aggregation in one of the keys
XXX: have column-oriented / nested tables to avoid keys duplication? how is this compatible with secondary indices ?}
connect map to its delta to use them
recursion = non-recursive with fixed \# iterations. orthogonal serie of maps
\begin{verbatim}
Goal:
=> inflationary semantics, what's cleanest language ?
look at orchestra (datalog + incrementally) [not very interesting]
- explicit deltas, use cases, triggers, active dbs
- what make it easier to do incrementalization easier
\end{verbatim}

--------------------------------------------------------------




% Bibliography
\bibliographystyle{plain} % acm
\def\pdfurl#1{\href{#1}{\footnotesize pdf}}
{\small \bibliography{../inc/bibliography.bib}}
\end{document}